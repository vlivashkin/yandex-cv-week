{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8F28mYbZJUo"
   },
   "source": [
    "*(to use GPU in colab go to Runtime -> Change Runtime Type and change the hardware accelerator)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUQ4miJsADfn"
   },
   "source": [
    "Только вчера закончился долгожданный посвят, но времени на отдых нет — до дедлайна по Variational Autoencoders всего 4 часа! Вы открываете ноутбук, готовясь внести последние штрихи, но с ужасом понимаете: задание в хаосе. Часть кода исчезла, а оставшиеся строки пестрят ошибками. В каком же состоянии Вы были, когда работали над этим вчера? Время неумолимо бежит, и теперь нужно срочно все исправить и успеть обучить модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "x_Dd0j4pcw9-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch version 2.3.0+cu121\n",
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "# some prelimenaries\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "torch.set_num_threads(16)\n",
    "torch.manual_seed(0)\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "print('Using torch version {}'.format(torch.__version__))\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wigquq3OADfo"
   },
   "source": [
    "Эти составители задания явно не желали облегчить Вам жизнь! Подсунули сломанный MNIST, нужно возиться с размерностью. И как будто этого недостаточно, ведь для восстановления её нельзя пользоваться любыми вспомогательными функциями из PyTorch и NumPy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "7laPQ52jADfo"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Union, List, Any\n",
    "\n",
    "def transpose_from_scratch(\n",
    "    lst: Union[List[List[Any]], torch.Tensor]\n",
    ") -> torch.Tensor:\n",
    "    s1, s2 = len(lst), len(lst[0])\n",
    "    result = [[0] * s1 for _ in range(s2)]\n",
    "    for i1, row in enumerate(lst):\n",
    "        for i2, item in enumerate(row):\n",
    "            result[i2][i1] = item\n",
    "    return torch.tensor(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7laPQ52jADfo"
   },
   "source": [
    "Фух, ну и пришлось повозиться. Теперь осталось только настроить загрузчики тренировочных и тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 1, 28])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "r5tFoBLdx-RT"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransposed_mnist_train.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mtranspose_from_scratch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_data)\n\u001b[1;32m      5\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader\n",
      "Cell \u001b[0;32mIn[51], line 12\u001b[0m, in \u001b[0;36mtranspose_from_scratch\u001b[0;34m(lst)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i2, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(row):\n\u001b[1;32m     11\u001b[0m         result[i2][i1] \u001b[38;5;241m=\u001b[39m item\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "train_data = torch.load(\"transposed_mnist_train.pt\")\n",
    "train_data = transpose_from_scratch(train_data)\n",
    "\n",
    "train_loader = DataLoader(train_data)\n",
    "test_loader = DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6YjhnVjADfo"
   },
   "source": [
    "# Вариационные автоэнкодеры\n",
    "\n",
    "Ну вот, Вы наконец добрались до самой важной части. Теперь нужно разобраться с реализацией VAE на MNIST и поправить все косяки, которые Вы наделали вчера, чтобы обучение прошло нормально и тестовый loss был в порядке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCGwVlZWdUA-"
   },
   "source": [
    "# Распределения для вариационных автоэнкодеров\n",
    "\n",
    "Воспоминания со вчерашнего дня возвращаются медленно, поэтому освежим необходимые для выполнения задания основы. Вам понадобятся два типа распределений для вероятностной модели:\n",
    "- **Для z**: используйте вектор независимых [нормально распределённых](https://pytorch.org/docs/stable/distributions.html#normal)  величин.\n",
    "- **Для x**: используйте вектор независимых случайных величин с распределением [Бернулли](https://pytorch.org/docs/stable/distributions.html#bernoulli).\n",
    "\n",
    "По умолчанию, соответствующие классы в PyTorch моделируют тензор независимых случайных величин. Чтобы представить матрицу таких величин как батч случайных векторов, можно использовать класс [Independent](https://pytorch.org/docs/stable/distributions.html#independent).\n",
    "\n",
    "### Распределение Бернулли\n",
    "\n",
    "Лучше инициализировать класс Бернулли **логитами**, а не вероятностями. Это помогает избежать нестабильности при вычислении логарифма вероятности.\n",
    "\n",
    "В этом задании Вам будет нужно использовать этот класс для моделирования $p(x \\mid z)$, параметризованного выходом декодера. Для вычисления функции потерь вам нужно будет использовать метод *log_prob()* для вычисления $\\log p(x \\mid z)$ на входных изображениях.\n",
    "\n",
    "### Нормальное распределение\n",
    "\n",
    "Вы будете использовать этот класс для определения распределения $q(z \\mid x)$ и распределения скрытой переменной $p(z)$.\n",
    "- Для функции потерь используйте метод *log_prob()*.\n",
    "- Чтобы сгенерировать выборку из $q(z \\mid x)$, которую затем можно передать в декодер, используйте метод сэмплирования, реализующий трюк репараметризации. При этом выборка вычисляется как $z = \\mu(x) + \\varepsilon \\odot \\sigma(x)$, где $\\varepsilon$ — стандартный гауссов шум.\n",
    "\n",
    "Здесь $\\odot$ обозначает поэлементное умножение.\n",
    "\n",
    "Следует отметить, что метод сэмплирования (rsample), реализующий [трюк репараметризации](https://runebook.dev/en/articles/pytorch/distributions/torch.distributions.half_normal.HalfNormal.has_rsample), отличается от стандартного метода выборки и специально предназначен для корректного учета градиентов, что особенно важно при обучении моделей, таких как вариационные автоэнкодеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9r_hPaHx0Jz1"
   },
   "outputs": [],
   "source": [
    "from torch.distributions import Normal, Bernoulli, Independent, constraints\n",
    "Bernoulli.support = constraints.interval(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wtFSf25dXjx"
   },
   "source": [
    "# Вариационные автоэнкодеры\n",
    "\n",
    "Вариационный автоэнкодер состоит из двух основных компонентов. Первая компонента - вероятностная модель для наблюдений:\n",
    "\\begin{align}\n",
    "& p(x, z \\mid \\theta) =  p(z) p(x \\mid z, \\theta) \\\\\n",
    "& p(z) = \\mathcal N(z \\mid 0, I) \\\\\n",
    "& p(x \\mid z, \\theta) = \\prod_{i = 1}^D p_i(z, \\theta)^{x_i} (1 - p_i(z, \\theta))^{1 - x_i}.\n",
    "\\end{align}\n",
    "\n",
    "Здесь $p(z)$ - нормальное распределение со средним $0$ и единичной ковариацией, а $p(x \\mid z, \\theta)$ моделируется как произведение распределений Бернулли для каждого элемента данных.\n",
    "\n",
    "Вторая компонента - вариационное приближение, которое используется для вычисления нижней границы на маргинальное правдоподобие (вариационные автоэнкодеры используют отрицательную нижнюю границу в качестве функции потерь)\n",
    "\\begin{equation}\n",
    "q(z \\mid x, \\phi) = \\mathcal N(z \\mid \\mu(x, \\phi), \\operatorname{diag}(\\sigma^2(x, \\phi))).\n",
    "\\end{equation}\n",
    "\n",
    "Нижняя граница для вероятности наблюдения $x$ из мини-батча выражается как:\n",
    "$$ \\mathcal L(x, \\theta, \\phi) = \\mathbb E_{q(z \\mid x, \\phi)} \\left[ \\log p(x \\mid z, \\phi) + \\log p(z) - \\log q(z \\mid x, \\theta) \\right] $$\n",
    "\n",
    "Однако вычислить это математическое ожидания напрямую сложно. Стандартный подход - аппроксимировать его с помощью оценки Монте-Карло с одним сэмплом:\n",
    "\\begin{align*}\n",
    "\\log p(x \\mid z_0, \\phi) + \\log p(z_0) - \\log q(z_0 \\mid x, \\theta) \\\\\n",
    "z_0 = \\mu(x, \\phi) + \\sigma^2(x, \\phi)^T \\varepsilon_0 \\\\\n",
    "\\varepsilon_0 \\sim \\mathcal N(0, I)\n",
    "\\end{align*}\n",
    "\n",
    "Для обучения модели мы усредняем значения нижней границы по мини-батчу и затем максимизируем это среднее с помощью градинтного подъема:\n",
    "$$ \\frac{1}{N} \\sum_{n=1}^N \\log p(x_n \\mid z_n, \\phi) + \\log p(z_n) - \\log q(z_n \\mid x_n, \\theta) \\rightarrow \\max_{\\theta, \\phi} $$\n",
    "\n",
    "## Энкодер и декодер\n",
    "\n",
    "Распределение $q(z\\mid x, \\theta)$ называется **энкодером**, так как оно кодирует данные $x$ в латентное представление $z$. Распределение $p(x\\mid z, \\phi)$ называется **декодером**, поскольку оно декодируем латентное представление обратно в данные $x$.\n",
    "\n",
    "Для параметризации этих распределений используются для нейронные сети:\n",
    "- **enc** принимает на вход $x$ и возвращает вектор размерности $2\\times d$, который задаёт среднее $\\mu(x, \\phi)$ и стандартное отклонение $\\sigma(x, \\phi)$ для распределения $q(z\\mid x,\\theta)$.\n",
    "- **dec** принимает на вход латентное представление $z$ и возвращает логиты для распределения $p(x\\mid z,\\phi)$.\n",
    "\n",
    "Структура вычислительного графа вариационного автоэнкодера похожа на обычный автоэнкодер, но с добавлением стохастической переменной $\\varepsilon$:\n",
    "\n",
    "![vae](https://github.com/Berdash/CV_notebook/blob/main/vae.png?raw=true)\n",
    "\n",
    "К сожалению, даже если архитектура когда была в задании, вы ее успели удалить, чтобы написать свою.\n",
    "\n",
    "**Ожидается**, что:\n",
    "Вы не будете менять размерности на входе, выходе и на скрытом слое, а также будете в своей реализации четко следовать тексту ниже\n",
    "\n",
    "**Энкодер** будет принимать на вход изображение, развернутое в вектор длины D = 28 * 28, и преобразовывать его в латентное представление.\n",
    "Архитектура должна включать всего три линейных слоя (один входной, один выходной и один скрытый), nn.Linear и две функции активации nn.ReLU.\n",
    "Последний слой должен возвращать вектор размерности 2 * d, где d — размерность латентного пространства. Этот вектор будет использоваться для вычисления среднего и стандартного отклонения в репараметризации.\n",
    "\n",
    "**Декодер** будет принимать на вход латентное представление размерности d и восстанавливать его в изображение размерности D.\n",
    "Декодер должен опять же включать всего три линейных слоя (один входной, один выходной и один скрытый), nn.Linear и две функции активации nn.ReLU.\n",
    "Последний слой должен возвращать вектор размерности D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "XnxFqNpbbIZs"
   },
   "outputs": [],
   "source": [
    "d, nh, D = 32, 200, 28 * 28\n",
    "\n",
    "enc = nn.Sequential(\n",
    "    nn.Linear(D, nh),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(nh, nh),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(nh, 2 * d),\n",
    ").to(device)\n",
    "\n",
    "dec = nn.Sequential(\n",
    "    nn.Linear(d, nh),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(nh, nh),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(nh, D),\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784])\n",
      "torch.Size([64])\n",
      "torch.Size([784])\n"
     ]
    }
   ],
   "source": [
    "vec = torch.zeros(D).to(device)\n",
    "print(vec.shape)\n",
    "latent = enc(vec)\n",
    "print(latent.shape)\n",
    "res = dec(latent[:32])\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xqmyAtbfmhG"
   },
   "source": [
    "## Функция потерь вариационного автоэнкодера\n",
    "\n",
    "Вот мы и добрались до того самого места, где ваши руки вчера особенно порезвились! Здесь явно спрятались три ошибки — сумеете их отыскать? Подсказка: теория может стать вашим лучшим другом в этом поиске!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "ymwPo9E3erVB"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Independent, Normal, Bernoulli\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "d, nh, D = 32, 200, 28 * 28\n",
    "\n",
    "def loss_vae(x, encoder, decoder):\n",
    "    \"\"\"\n",
    "    returns\n",
    "    1. the avergave value of negative ELBO across the minibatch x\n",
    "    2. and the output of the decoder\n",
    "    \"\"\"\n",
    "    batch_size = x.size(0)\n",
    "    encoder_output = encoder(x)\n",
    "    pz = Independent(Normal(loc=torch.zeros(batch_size, d).to(device),\n",
    "                            scale=torch.ones(batch_size, d).to(device)),\n",
    "                     reinterpreted_batch_ndims=1)\n",
    "    qz_x = Independent(Normal(loc=encoder_output[:, :d],\n",
    "                              scale=torch.exp(encoder_output[:, d:])),\n",
    "                       reinterpreted_batch_ndims=1)\n",
    "    z = qz_x.rsample()\n",
    "\n",
    "    decoder_output = decoder(z)\n",
    "    px_z = Independent(Bernoulli(logits=decoder_output),\n",
    "                       reinterpreted_batch_ndims=1)\n",
    "\n",
    "    loss = -(px_z.log_prob(x) + pz.log_prob(z) - qz_x.log_prob(z)).mean()\n",
    "    return loss, decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(543.2725, device='cuda:0', grad_fn=<NegBackward0>),\n",
       " tensor([[-0.1171,  0.0017,  0.0487,  ...,  0.0381,  0.0022,  0.1027],\n",
       "         [-0.0902,  0.1205, -0.0109,  ...,  0.0864,  0.0257,  0.1480],\n",
       "         [-0.0923,  0.1188,  0.0037,  ...,  0.2029, -0.0338,  0.2177],\n",
       "         ...,\n",
       "         [ 0.0439, -0.0590,  0.1533,  ..., -0.0112,  0.0676,  0.1639],\n",
       "         [-0.0528,  0.0793,  0.1030,  ..., -0.0213, -0.0590,  0.1132],\n",
       "         [-0.0176,  0.0441,  0.0101,  ...,  0.0643, -0.0327,  0.1318]],\n",
       "        device='cuda:0', grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = torch.zeros([10, 28 * 28]).to(device)\n",
    "loss_vae(vec, enc, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "U-7zR3JRO4jC"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Пример данных: Перемещаем данные на устройство\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m x_sample \u001b[38;5;241m=\u001b[39m \u001b[43mtest_loader\u001b[49m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m      5\u001b[0m x_sample \u001b[38;5;241m=\u001b[39m x_sample\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, D)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Отправляем модели на нужное устройство\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Пример данных: Перемещаем данные на устройство\n",
    "x_sample = test_loader.dataset.data[0].float().unsqueeze(0).to(device) / 255.0\n",
    "x_sample = x_sample.view(-1, D).to(device)\n",
    "\n",
    "# Отправляем модели на нужное устройство\n",
    "enc = enc.to(device)\n",
    "dec = dec.to(device)\n",
    "with torch.no_grad():\n",
    "    loss_value, _ = loss_vae(x_sample, enc, dec)\n",
    "\n",
    "print(f\"Loss: {loss_value.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIMpMloYfyJT"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLI_soZRfzBM"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def train_model(loss, model, batch_size=100, num_epochs=3, learning_rate=1e-3):\n",
    "    gd = torch.optim.Adam(\n",
    "        chain(*[x.parameters() for x in model\n",
    "                if (isinstance(x, nn.Module) or isinstance(x, nn.Parameter))]),\n",
    "        lr=learning_rate)\n",
    "    train_losses = []\n",
    "    test_results = []\n",
    "    for _ in range(num_epochs):\n",
    "        for i, (batch, _) in enumerate(train_loader):\n",
    "            total = len(train_loader)\n",
    "            gd.zero_grad()\n",
    "            batch = batch.view(-1, D).to(device)\n",
    "            loss_value, _ = loss(batch, *model)\n",
    "            loss_value.backward()\n",
    "            train_losses.append(loss_value.item())\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print('\\rTrain loss:', train_losses[-1],\n",
    "                      'Batch', i + 1, 'of', total, ' ' * 10, end='', flush=True)\n",
    "            gd.step()\n",
    "        test_loss = 0.\n",
    "        for i, (batch, _) in enumerate(test_loader):\n",
    "            batch = batch.view(-1, D).to(device)\n",
    "            batch_loss, _ = loss(batch, *model)\n",
    "            test_loss += (batch_loss - test_loss) / (i + 1)\n",
    "        print('\\nTest loss after an epoch: {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBdmTPTax-RV"
   },
   "source": [
    "Правильная реализация должна выдавать тестовый лосс где-то в районе 104.\n",
    "\n",
    "А вот 120+ — это уже совсем не то, что нам надо, так что не расслабляемся! Удачи!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPjL_TOpf17s"
   },
   "outputs": [],
   "source": [
    "train_model(loss_vae, model=[enc, dec], num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McWlphgdf5ip"
   },
   "source": [
    "## Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXg47-euADfr"
   },
   "source": [
    "Вы уже на финишной прямой! Давайте взглянем, какие картинки у нас генерируются, и можно продолжать праздновать посвят!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pgFFrXPxkNAh"
   },
   "outputs": [],
   "source": [
    "def sample_vae(dec, n_samples=50):\n",
    "    with torch.no_grad():\n",
    "        samples = torch.sigmoid(dec(torch.randn(n_samples, d).to(device)))\n",
    "        samples = samples.view(n_samples, 28, 28).cpu().numpy()\n",
    "    return samples\n",
    "\n",
    "def plot_samples(samples, h=5, w=10):\n",
    "    fig, axes = plt.subplots(nrows=h,\n",
    "                             ncols=w,\n",
    "                             figsize=(int(1.4 * w), int(1.4 * h)),\n",
    "                             subplot_kw={'xticks': [], 'yticks': []})\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        ax.imshow(samples[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jX7z79vpAUp1"
   },
   "outputs": [],
   "source": [
    "plot_samples(sample_vae(dec=dec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVfp4hfbf66d"
   },
   "outputs": [],
   "source": [
    "def plot_reconstructions(loss, model):\n",
    "    with torch.no_grad():\n",
    "        batch = (test_loader.dataset.data[:25].float() / 255.)\n",
    "        batch = batch.view(-1, D).to(device)\n",
    "        _, rec = loss(batch, *model)\n",
    "        rec = torch.sigmoid(rec)\n",
    "        rec = rec.view(-1, 28, 28).cpu().numpy()\n",
    "        batch = batch.view(-1, 28, 28).cpu().numpy()\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=5, ncols=10, figsize=(14, 7),\n",
    "                                 subplot_kw={'xticks': [], 'yticks': []})\n",
    "        for i in range(25):\n",
    "            if i % 5 == 0:\n",
    "                axes[i % 5, 2 * (i // 5)].set_title(\"Orig\")\n",
    "                axes[i % 5, 2 * (i // 5) + 1].set_title(\"Recon\")\n",
    "            axes[i % 5, 2 * (i // 5)].imshow(batch[i], cmap='gray')\n",
    "            axes[i % 5, 2 * (i // 5) + 1].imshow(rec[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fn1cLF_BgAN2"
   },
   "outputs": [],
   "source": [
    "plot_reconstructions(loss_vae, [enc, dec])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "spiritme_ml",
   "language": "python",
   "name": "spiritme_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
